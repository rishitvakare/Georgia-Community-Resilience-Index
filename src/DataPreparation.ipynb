{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import pathlib\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from shapely.geometry import shape\n",
    "import feedparser\n",
    "import urllib.parse\n",
    "import requests\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=pathlib.Path('.') / '.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enriched socioeconomic data to data/socioeconomic_full.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------\n",
    "# census_pull.py \n",
    "# --------------------\n",
    "# Fetches 2021 ACS 5-Year data for Georgia counties:\n",
    "# --> poverty & population (B17001)\n",
    "# --> education levels (B15003)\n",
    "# --> housing cost burden (B25070)\n",
    "# Computes the SEV by taking the mean of all three metrics\n",
    "# Resiliency Score = 1 - SEV\n",
    "# Writes all of the data to data/socioeconomic_full.csv\n",
    "\n",
    "\n",
    "# Load API key\n",
    "API_KEY = os.getenv(\"CENSUS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"Please enter your CENSUS_API_KEY environment variable\")\n",
    "\n",
    "# Define endpoint & variables\n",
    "BASE_URL = 'https://api.census.gov/data/2021/acs/acs5'\n",
    "# Poverty: B17001_002E = poverty estimate, B17001_001E = total population\n",
    "# Education: B15003_001E = total pop 25+, B15003_002E..B15003_015E = pop without HS diploma\n",
    "# Housing cost burden: B25070_010E = households paying >30% income, B25070_001E = total units\n",
    "edu_fields = [f'B15003_{i:03d}E' for i in range(2, 16)]  # 002E to 015E\n",
    "VARS = [\n",
    "    'NAME',\n",
    "    'B17001_002E', 'B17001_001E',\n",
    "    'B15003_001E', *edu_fields,\n",
    "    'B25070_010E', 'B25070_001E'\n",
    "]\n",
    "params = {\n",
    "    'get': ','.join(VARS),\n",
    "    'for': 'county:*',\n",
    "    'in': 'state:13',  # Georgia\n",
    "    'key': API_KEY\n",
    "}\n",
    "\n",
    "# Request data\n",
    "response = requests.get(BASE_URL, params=params)\n",
    "response.raise_for_status()\n",
    "records = response.json()\n",
    "\n",
    "# Build DataFrame\n",
    "columns = records[0]\n",
    "rows = records[1:]\n",
    "data_frame = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "num_cols = ['B17001_002E','B17001_001E','B15003_001E','B25070_010E','B25070_001E'] + edu_fields\n",
    "for col in num_cols:\n",
    "    data_frame[col] = pd.to_numeric(data_frame[col], errors='coerce')\n",
    "\n",
    "# Compute derived metrics\n",
    "data_frame['poverty_rate'] = data_frame['B17001_002E'] / data_frame['B17001_001E']\n",
    "data_frame['education_no_hs_rate'] = data_frame[edu_fields].sum(axis=1) / data_frame['B15003_001E']\n",
    "data_frame['housing_cost_burden'] = data_frame['B25070_010E'] / data_frame['B25070_001E']\n",
    "\n",
    "# Select & rename columns\n",
    "output = data_frame[['NAME','state','county','poverty_rate','education_no_hs_rate','housing_cost_burden']].copy()\n",
    "output = output.rename(columns={\n",
    "    'NAME': 'County Name',\n",
    "    'state': 'State',\n",
    "    'poverty_rate': 'Poverty Rate',\n",
    "    'education_no_hs_rate': 'No_HS_Education', \n",
    "    'housing_cost_burden': \"Housing_Cost_Burden\"\n",
    "\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs('data', exist_ok=True)\n",
    "out_path = 'data/socioeconomic_full.csv'\n",
    "output.to_csv(out_path, index=False)\n",
    "print(f\"Saved enriched socioeconomic data to {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved socioeconomic SEV data to data/socioeconomic_sev.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# socioeconomic_sev.py\n",
    "# --------------------\n",
    "# Purpose:\n",
    "#   Calculate the Socioeconomic Vulnerability Score (SEV) and its resilience component\n",
    "#   from an enriched Census dataset (socioeconomic_full.csv).\n",
    "#   The script applies min-max normalization to three indicators:\n",
    "#     - poverty_rate\n",
    "#     - education_no_hs_rate\n",
    "#     - housing_cost_burden\n",
    "#   and then computes SEV and Resilience_Socio = 1 - SEV.\n",
    "#\n",
    "# Input:\n",
    "#   data/socioeconomic_full.csv\n",
    "# Output:\n",
    "#   data/socioeconomic_sev.csv\n",
    "\n",
    "# Load enriched socioeconomic data\n",
    "input_path = 'data/socioeconomic_full.csv'\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"Missing input file: {input_path}\")\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Normalize indicators via min-max to [0,1]\n",
    "metrics = ['Poverty Rate', 'No_HS_Education', 'Housing_Cost_Burden']\n",
    "for metric in metrics:\n",
    "    minimum = df[metric].min()\n",
    "    maximum = df[metric].max()\n",
    "    # Avoid division by zero if all values are equal\n",
    "    if maximum > minimum:\n",
    "        df[f'norm_{metric}'] = (df[metric] - minimum) / (maximum - minimum)\n",
    "    else:\n",
    "        df[f'norm_{metric}'] = 0.0\n",
    "\n",
    "# Compute Socioeconomic Vulnerability Score (SEV) as the average of normalized metrics\n",
    "df['SEV'] = df[[f'norm_{metric}' for metric in metrics]].mean(axis=1)\n",
    "\n",
    "# 1 - SEV = Resiliency Score\n",
    "df['Resilience_Socio'] = 1 - df['SEV']\n",
    "\n",
    "# Save the results\n",
    "os.makedirs('data', exist_ok=True)\n",
    "output_path = 'data/socioeconomic_sev.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved socioeconomic SEV data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_access_score.csv written\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# usda_loader.py\n",
    "# --------------------\n",
    "# Purpose:\n",
    "#   Calculate the Food Insecurity Score as well as the Food Resilience Score\n",
    "#   Combine enriched socioeconomic data with USDA Food Access Research Atlas data\n",
    "#   to compute a county-level Food Insecurity Score (FIS) and its resilience food metric\n",
    "# Input:\n",
    "#   - data/socioeconomic_full.csv --> counties with poverty, education, and housing metrics.\n",
    "#   - data/2019 Food Access Research Atlas Data/Food Access Research Atlas.csv --> tract-level LILA flags and low-access percentages.\n",
    "# Output:\n",
    "#   data/food_access_score.csv\n",
    "\n",
    "# Load and pads the FIPS with zeros\n",
    "census = pd.read_csv('data/socioeconomic_full.csv', dtype=str)\n",
    "census['county'] = census['county'].str.zfill(3)\n",
    "\n",
    "atlas = pd.read_csv('data/2019 Food Access Research Atlas Data/Food Access Research Atlas.csv', dtype=str, low_memory=False)\n",
    "# Extract FIPS\n",
    "atlas['State']  = atlas['CensusTract'].str[:2]\n",
    "atlas['county'] = atlas['CensusTract'].str[2:5]\n",
    "atlas = atlas[atlas['State']=='13']  # Georgia only\n",
    "# Casts LILA (Low Income, Low Access)\n",
    "atlas['LILATracts_1And10'] = atlas['LILATracts_1And10'].astype(int)\n",
    "\n",
    "# Calculates the fraction of LILA tracts that are flagged\n",
    "county_flag = (\n",
    "    atlas.groupby(['State','county'])\n",
    "         .agg(frac_lila_tracts=('LILATracts_1And10','mean'))\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# Merges with the socioeconomic_full.csv file we made earlier\n",
    "merged = census.merge(county_flag, on=['State','county'], how='left')\n",
    "\n",
    "# Renames columns\n",
    "merged = merged.rename(columns={'frac_lila_tracts':'FIS'})\n",
    "merged['Resilience_Food'] = 1 - merged['FIS']\n",
    "\n",
    "merged.to_csv('data/food_access_score.csv', index=False)\n",
    "print(\"food_access_score.csv written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/healthcare_uninsured_counts.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Purpose:\n",
    "#   Query the Census ACS API to fetch the **raw uninsured count**\n",
    "#   among residents under 65 for every county in Georgia.\n",
    "#   Doing the population under 65 because after 65, Medicare is available\n",
    "#\n",
    "\n",
    "# Load your Census API key from the environment\n",
    "API_KEY = os.getenv('HEALTHCARE_API_KEY')\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"Please set the HEALTHCARE_API_KEY environment variable.\")\n",
    "\n",
    "# Define the ACS endpoint and variables\n",
    "BASE_URL = 'https://api.census.gov/data/2021/acs/acs5'\n",
    "VARS = {\n",
    "    'total_under65': 'B27010_001E',\n",
    "    'uninsured_under65': 'B27010_017E'\n",
    "}\n",
    "params = {\n",
    "    'get': f\"{VARS['total_under65']},{VARS['uninsured_under65']},NAME\",\n",
    "    'for': 'county:*',\n",
    "    'in': 'state:13',   # 13 = Georgia\n",
    "    'key': API_KEY\n",
    "}\n",
    "\n",
    "# Send request\n",
    "resp = requests.get(BASE_URL, params=params)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "\n",
    "# Parse into DataFrame\n",
    "columns = data[0]\n",
    "rows = data[1:]\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Convert to numeric\n",
    "df['total_under65'] = df[VARS['total_under65']].astype(int)\n",
    "df['uninsured_count'] = df[VARS['uninsured_under65']].astype(int)\n",
    "df['county_name'] = df['NAME']\n",
    "df['state'] = df['state']\n",
    "df['county'] = df['county']\n",
    "\n",
    "# Select & reorder columns\n",
    "out = df[['state', 'county', 'county_name', 'uninsured_count', 'total_under65']]\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs('data', exist_ok=True)\n",
    "output_path = 'data/healthcare_uninsured_counts.csv'\n",
    "\n",
    "out = out.rename(columns={\n",
    "    'state': 'StateFIPS',\n",
    "    'county': 'CountyFIPS',\n",
    "    'county_name': 'County Name',\n",
    "    'uninsured_count': 'Uninsured Population Under 65',\n",
    "    'total_under65': 'Total Population Under 65'\n",
    "})\n",
    "\n",
    "\n",
    "out.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved healthcare resilience data to data/healthcare_resilience.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# healthcare_score.py\n",
    "# --------------------\n",
    "#Purpose:\n",
    "#    - Load county-level uninsured counts under 65 (healthcare_uninsured_counts.csv)\n",
    "#    - Compute the uninsured rate = Uninsured population / Total population under 65\n",
    "#    - Normalize uninsured_rate into [0,1] via min-max method into NormInsured\n",
    "#    - Derive Resilience_Health = 1 - Normalized_Uninsured\n",
    "#    - Output augmented CSV with new columns: uninsured_rate, NormUninsured, Resilience_Health\n",
    "#Inputs:\n",
    "#    - data/healthcare_uninsured_counts.csv\n",
    "#Outputs:\n",
    "#    - data/healthcare_resilience.csv\n",
    "\n",
    "# Paths\n",
    "INPUT_CSV  = 'data/healthcare_uninsured_counts.csv'\n",
    "OUTPUT_CSV = 'data/healthcare_resilience.csv'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Compute uninsured rate\n",
    "df['uninsured_rate'] = df['Uninsured Population Under 65'] / df['Total Population Under 65']\n",
    "\n",
    "# Normalize uninsured_rate via min-max\n",
    "minimum_val = df['uninsured_rate'].min()\n",
    "maximum_val = df['uninsured_rate'].max()\n",
    "if maximum_val > minimum_val:\n",
    "    df['Normalized_Uninsured'] = (df['uninsured_rate'] - minimum_val) / (maximum_val - minimum_val)\n",
    "else:\n",
    "    df['Normalized_Uninsured'] = df['uninsured_rate']\n",
    "\n",
    "# Derive resilience\n",
    "df['Resilience_Health'] = 1 - df['Normalized_Uninsured']\n",
    "\n",
    "# Save results\n",
    "os.makedirs('data', exist_ok=True)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved healthcare resilience data to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final CRI to data/community_resilience_index.csv\n"
     ]
    }
   ],
   "source": [
    "# Will compute the final CRI score\n",
    "# Will apply equal weights (1/3) to each of the three metrics:  \n",
    "#   - Food Insecurity Score (FIS)\n",
    "#   - Healthcare Uninsured Count\n",
    "#   - Socioeconomic Vulnerability (SEV)\n",
    "\n",
    "# For now, we are keeping the default weights = 1/3\n",
    "\n",
    "# If case studies/research show one metric is more important, we can adjust the weights later\n",
    "\n",
    "data_directory = pathlib.Path('data')\n",
    "socioeconomic_sev = data_directory / 'socioeconomic_sev.csv'\n",
    "healthcare_sev = data_directory / 'healthcare_resilience.csv'\n",
    "food_access_score = data_directory / 'food_access_score.csv'\n",
    "OUTPUT_CSV = data_directory / 'community_resilience_index.csv'\n",
    "\n",
    "# Load & rename FIPS columns\n",
    "socio_df = pd.read_csv(socioeconomic_sev, dtype=str)\n",
    "# Rename uppercase 'State' â†’ 'state'\n",
    "socio_df = socio_df.rename(columns={'State': 'state'})\n",
    "food_df  = pd.read_csv(food_access_score, dtype=str)\n",
    "# Rename uppercase 'State' â†’ 'state'\n",
    "food_df  = food_df.rename(columns={'State': 'state'})\n",
    "health_df= pd.read_csv(healthcare_sev, dtype=str)\n",
    "# Rename StateFIPS/CountyFIPS â†’ state/county\n",
    "health_df = health_df.rename(columns={\n",
    "    'StateFIPS': 'state',\n",
    "    'CountyFIPS': 'county'\n",
    "})\n",
    "\n",
    "# Zero-pad FIPS strings\n",
    "for dataframe in (socio_df, food_df, health_df):\n",
    "    dataframe['state']  = dataframe['state'].str.zfill(2)\n",
    "    dataframe['county'] = dataframe['county'].str.zfill(3)\n",
    "\n",
    "# Merge three components on (state, county)\n",
    "merged_file = (\n",
    "    socio_df\n",
    "    .merge(food_df[['state','county','Resilience_Food']], on=['state','county'], how='left')\n",
    "    .merge(health_df[['state','county','Resilience_Health']], on=['state','county'], how='left')\n",
    ")\n",
    "\n",
    "# Convert all resilience columns to numeric\n",
    "for col in ['Resilience_Socio','Resilience_Food','Resilience_Health']:\n",
    "    merged_file[col] = pd.to_numeric(merged_file[col], errors='coerce')\n",
    "\n",
    "# Computes the CRI with equal weights\n",
    "w1 = w2 = w3 = 1/3\n",
    "merged_file['CRI'] = (\n",
    "    w1 * merged_file['Resilience_Socio'] +\n",
    "    w2 * merged_file['Resilience_Food'] +\n",
    "    w3 * merged_file['Resilience_Health']\n",
    ")\n",
    "\n",
    "merged_file['state_name']  = 'Georgia'\n",
    "\n",
    "# Only keeps the relevant variables for the CRI\n",
    "output = merged_file[[\n",
    "    'state',        \n",
    "    'state_name',    \n",
    "    'county',        \n",
    "    'County Name',   \n",
    "    'Resilience_Socio',\n",
    "    'Resilience_Food',\n",
    "    'Resilience_Health',\n",
    "    'CRI'\n",
    "]]\n",
    "\n",
    "# Renames the columns to be more descriptive\n",
    "output.columns = [\n",
    "    'StateFIPS',\n",
    "    'State Name',\n",
    "    'CountyFIPS',\n",
    "    'County Name',\n",
    "    'Socioeconomic Resilience',\n",
    "    'Food Resilience',\n",
    "    'Healthcare Resilience',\n",
    "    'Community Resilience Index (CRI)'\n",
    "]\n",
    "\n",
    "# 8) Save that\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "output.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved final CRI to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting interactive_dashboard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile interactive_dashboard.py\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from shapely.geometry import shape\n",
    "import feedparser\n",
    "import urllib.parse\n",
    "import requests\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set Streamlit page config\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "#\n",
    "# â”€â”€â”€ DATA & PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "HERE = Path('.')\n",
    "DATA_DIR = HERE / \"data\"\n",
    "CRI_CSV = DATA_DIR / \"community_resilience_index.csv\"\n",
    "GEOJSON = DATA_DIR / \"counties.geojson\"\n",
    "\n",
    "\n",
    "#\n",
    "# â”€â”€â”€ LOAD & PREP DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    dataframe = pd.read_csv(CRI_CSV, dtype=str)\n",
    "\n",
    "    # Build FIPS\n",
    "    dataframe[\"state\"]  = dataframe[\"StateFIPS\"].str.zfill(2)\n",
    "    dataframe[\"county\"] = dataframe[\"CountyFIPS\"].str.zfill(3)\n",
    "    dataframe[\"fips\"]   = dataframe[\"state\"] + dataframe[\"county\"]\n",
    "\n",
    "    # Numeric columns\n",
    "    for column in [\n",
    "        \"Socioeconomic Resilience\",\n",
    "        \"Food Resilience\",\n",
    "        \"Healthcare Resilience\",\n",
    "        \"Community Resilience Index (CRI)\"\n",
    "    ]:\n",
    "        dataframe[column] = pd.to_numeric(dataframe[column], errors=\"coerce\").round(4)\n",
    "\n",
    "    # Keep only Georgia (state FIPS == '13')\n",
    "    dataframe = dataframe[dataframe[\"state\"] == \"13\"].copy()\n",
    "\n",
    "    # Load geojson & compute centroids for the counties\n",
    "    gj = json.loads((GEOJSON).read_text())\n",
    "    cents = {}\n",
    "    for feat in gj[\"features\"]:\n",
    "        geoid = feat[\"properties\"][\"GEOID\"]\n",
    "        cent  = shape(feat[\"geometry\"]).centroid\n",
    "        cents[geoid] = (cent.y, cent.x)\n",
    "\n",
    "    # Returns the DataFrame, the GeoJSON, and the centroids\n",
    "    return dataframe, gj, cents\n",
    "\n",
    "# Load the data\n",
    "cri_df, counties_geojson, centroids = load_data()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# â”€â”€â”€ HELPER FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "\n",
    "# To calculate the distance between two lat/lon pairs using the Haversine formula (In handy for radius filtering)\n",
    "def haversine(a, b):\n",
    "    latitude1, longitude1 = a\n",
    "    latitude2, longitude2 = b\n",
    "    dist_lat = math.radians(latitude2 - latitude1)\n",
    "    dist_lon = math.radians(longitude2 - longitude1)\n",
    "    hsine = math.sin(dist_lat/2)**2 + math.cos(math.radians(latitude1)) \\\n",
    "        * math.cos(math.radians(latitude2)) * math.sin(dist_lon/2)**2\n",
    "    return 3958.8 * 2 * math.asin(math.sqrt(hsine))\n",
    "\n",
    "# Filter the CRI DataFrame based on a range\n",
    "def cri_range(low, high):\n",
    "    sub = cri_df[(cri_df[\"Community Resilience Index (CRI)\"] >= low) & (cri_df[\"Community Resilience Index (CRI)\"] <= high)]\n",
    "    return sub.sort_values(\"Community Resilience Index (CRI)\", ascending=False)\n",
    "\n",
    "# Parse the CRI range based on the user input in the chat bot\n",
    "def parse_cri_range(text: str):\n",
    "    txt = text.lower()\n",
    "    # between X and Y\n",
    "    mid = re.search(r\"between\\s*([0-9]*\\.?[0-9]+)\\s*(?:and|to)\\s*([0-9]*\\.?[0-9]+)\", txt)\n",
    "    if mid:\n",
    "        return float(mid.group(1)), float(mid.group(2))\n",
    "    # above X\n",
    "    mid = re.search(r\"above\\s*([0-9]*\\.?[0-9]+)\", txt)\n",
    "    if mid:\n",
    "        return float(mid.group(1)), 1.0\n",
    "    # below X\n",
    "    mid = re.search(r\"below\\s*([0-9]*\\.?[0-9]+)\", txt)\n",
    "    if mid:\n",
    "        return 0.0, float(mid.group(1))\n",
    "    raise ValueError(\"Sorry, I couldn't parse a CRI range from that question. \" \\\n",
    "    \"Please format your question in the example given above and try again.\")\n",
    "\n",
    "# Fetch the NOAA weather warnings for counties in Georgia that have an active warning\n",
    "@st.cache_data(ttl=300)\n",
    "def fetch_noaa_warnings():\n",
    "    noaa_url = \"https://api.weather.gov/alerts/active?area=GA\"\n",
    "    req = requests.get(noaa_url, timeout=10)\n",
    "    req.raise_for_status()\n",
    "    noaa_data = req.json()\n",
    "    warning_fips = set()\n",
    "    for feat in noaa_data[\"features\"]:\n",
    "        geocode = feat[\"properties\"].get(\"geocode\",{}) or {}\n",
    "        for code in geocode.get(\"SAME\", []):\n",
    "            # NWS SAME codes are 5-digit state+county FIPS (e.g. \"13057\")\n",
    "            if len(code) == 5 and code.startswith(\"13\"):\n",
    "                warning_fips.add(code)\n",
    "    return warning_fips\n",
    "\n",
    "@st.cache_data\n",
    "def compute_res_clusters(df, n_clusters=4):\n",
    "    # Through scikit-learn's KMeans, we can cluster the counties based on their resilience scores.\n",
    "    # We will use the four resilience scores as features for clustering.\n",
    "    X = df[[\n",
    "        \"Socioeconomic Resilience\",\n",
    "        \"Food Resilience\",\n",
    "        \"Healthcare Resilience\"\n",
    "    ]].to_numpy()\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    df2 = df.copy()\n",
    "    df2[\"cluster\"] = labels.astype(str)\n",
    "    return df2, kmeans\n",
    "\n",
    "# Compute the clusters\n",
    "clustered_df, kmeans_model = compute_res_clusters(cri_df)\n",
    "\n",
    "#\n",
    "# â”€â”€â”€ SIDEBAR : NEWS FEED + NOAA WARNINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "\n",
    "# Sidebar components\n",
    "with st.sidebar:\n",
    "\n",
    "    # Title for the sidebar\n",
    "    st.sidebar.markdown(\n",
    "    \"<div style='font-size:24px; font-weight:bold; margin-bottom:8px;'>ðŸ“° Live News & NOAA Warning Feed</div>\",\n",
    "    unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "    # Let's the user input keywords separated by commas \n",
    "    keyword_input = st.sidebar.text_input(\n",
    "        \"Enter keywords (comma-separated)\",\n",
    "        value=\"Social inequality\"\n",
    "    )\n",
    "\n",
    "    # Can pull up to 50 articles at a time\n",
    "    articles = st.sidebar.slider(\"Max articles to fetch\", 1, 50, 20)\n",
    "\n",
    "    # Builds the RSS search algorithm through google articles \n",
    "    terms = [keyword.strip() + \" Georgia\" for keyword in keyword_input.split(\",\") if keyword.strip()]\n",
    "    quote = urllib.parse.quote_plus(\" OR \".join(terms))\n",
    "    feed_urls = f\"https://news.google.com/rss/search?q={quote}&hl=en-US&gl=US&ceid=US:en\"\n",
    "    feed = feedparser.parse(feed_urls)\n",
    "\n",
    "\n",
    "    sidebar_entries = feed.entries[:articles]\n",
    "\n",
    "    # Pagination logic\n",
    "    if \"news_page\" not in st.session_state or st.session_state.get(\"news_query\") != feed_urls:\n",
    "        st.session_state.news_page = 1\n",
    "        st.session_state.news_query = feed_urls\n",
    "    curr_page = st.session_state.news_page\n",
    "    per_page = 5\n",
    "    total_pages = math.ceil(len(sidebar_entries) / per_page) or 1\n",
    "\n",
    "    # Just render the sidebar entries for the current page\n",
    "    start = (curr_page - 1) * per_page\n",
    "    end = start + per_page\n",
    "    for entry in sidebar_entries[start:end]:\n",
    "        date = entry.get(\"published\", \"\").split(\"T\")[0]\n",
    "        st.sidebar.markdown(\n",
    "            f\"**[{entry.title}]({entry.link})**  \\n*{date}*\"\n",
    "        )\n",
    "    \n",
    "    # Renders the page navigation buttons\n",
    "    previous_col, middle_col, next_col = st.sidebar.columns([1, 2, 1])\n",
    "    if previous_col.button(\"Â« Prev Page\") and curr_page > 1:\n",
    "        st.session_state.news_page -= 1\n",
    "    if next_col.button(\"Next Page Â»\") and curr_page < total_pages:\n",
    "        st.session_state.news_page += 1\n",
    "\n",
    "    middle_col.markdown(\n",
    "    f\"<div style='text-align: center; font-weight:600;'>Page {curr_page} of {total_pages}</div>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "    \n",
    "    \n",
    "#\n",
    "# â”€â”€â”€ MAIN LAYOUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#\n",
    "\n",
    "# Title centered\n",
    "st.markdown(\"<h1 style='text-align:center'>Georgia Community Resilience Index Dashboard</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "# Two-column layout\n",
    "# - Left: Filters and Chatbot\n",
    "# - Right: Map and Bar Chart\n",
    "left, right = st.columns([1,3], gap=\"large\")\n",
    "\n",
    "# Left column: Filters and Chatbot\n",
    "with left:\n",
    "    # Sets the subheader for the filters section\n",
    "    st.subheader(\"ðŸ”Ž Filters\")\n",
    "    # CRI slider filter\n",
    "    min_c, max_c = st.slider(\n",
    "        \"CRI range\",\n",
    "        float(cri_df[\"Community Resilience Index (CRI)\"].min()),\n",
    "        float(cri_df[\"Community Resilience Index (CRI)\"].max()),\n",
    "        (\n",
    "          float(cri_df[\"Community Resilience Index (CRI)\"].min()),\n",
    "          float(cri_df[\"Community Resilience Index (CRI)\"].max()),\n",
    "        )\n",
    "    )\n",
    "    # County and radius filters\n",
    "    county = st.selectbox(\"County\", [\"All\"]+sorted(cri_df[\"County Name\"].unique()))\n",
    "    radius = st.slider(\"Radius (mi)\", 1, 100, 25)\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    # Chatbot for CRI range queries\n",
    "    st.subheader(\"ðŸ’¬ Ask the CRI Bot\")\n",
    "    query = st.text_input(\"e.g. Which counties above 0.7?\")\n",
    "    if st.button(\"Run Chat\"):\n",
    "        try:\n",
    "            low, high = parse_cri_range(query)\n",
    "            df_out = cri_range(low, high)\n",
    "            st.write(df_out[[\"County Name\",\"Community Resilience Index (CRI)\"]])\n",
    "        except Exception as error:\n",
    "            st.error(error)\n",
    "\n",
    "# Right column: Map and Bar Chart\n",
    "with right:\n",
    "    # Pick your base: raw CRI vs. cluster\n",
    "    map_toggle = st.radio(\n",
    "        \"Color Map By:\",\n",
    "        [\"Community Resilience Index (CRI)\", \"Resilience Clusters\"],\n",
    "        index=0,\n",
    "    )\n",
    "\n",
    "    # If we are using clusters, we need to prepare the DataFrame for the clusters\n",
    "    # and show the cluster centers\n",
    "    if map_toggle == \"Resilience Clusters\":\n",
    "        centers = pd.DataFrame(\n",
    "            kmeans_model.cluster_centers_,\n",
    "            columns=[\n",
    "                \"Socioeconomic Resilience\",\n",
    "                \"Food Resilience\",\n",
    "                \"Healthcare Resilience\"\n",
    "            ],\n",
    "            index=[f\"Cluster {i}\" for i in range(len(kmeans_model.cluster_centers_))]\n",
    "        ).round(4)\n",
    "        st.subheader(\"Resilience Cluster Centers\")\n",
    "        st.table(centers)\n",
    "        \n",
    "        base = clustered_df.copy()\n",
    "        color_col = \"cluster\"\n",
    "    else:\n",
    "        base = cri_df.copy()\n",
    "        color_col = \"Community Resilience Index (CRI)\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Prepare the map DataFrame\n",
    "    # Filter the base DataFrame based on the CRI range and county selection\n",
    "    df_map = base[(base[\"Community Resilience Index (CRI)\"] >= min_c) & (base[\"Community Resilience Index (CRI)\"] <= max_c)].copy()\n",
    "    if county!=\"All\":\n",
    "        center = centroids[cri_df.loc[cri_df[\"County Name\"]==county,\"fips\"].iloc[0]]\n",
    "        df_map[\"dist\"] = df_map[\"fips\"].map(lambda f: haversine(center, centroids[f]))\n",
    "        df_map = df_map[df_map[\"dist\"] <= radius]\n",
    "\n",
    "    # Warning fip codes are received from the helper function calling the NOAA API\n",
    "    warning_fips = fetch_noaa_warnings()\n",
    "    df_map[\"warning\"] = df_map[\"fips\"].isin(warning_fips)\n",
    "\n",
    "\n",
    "    # Build the choropleth map using Plotly Express\n",
    "\n",
    "    # If the map toggle is resilience cluster\n",
    "    if map_toggle == \"Resilience Clusters\":\n",
    "        fig = px.choropleth(\n",
    "            df_map,\n",
    "            geojson=counties_geojson,\n",
    "            locations=\"fips\",\n",
    "            featureidkey=\"properties.GEOID\",\n",
    "            color=\"cluster\",\n",
    "            scope=\"usa\",\n",
    "            category_orders={ \"cluster\": sorted(df_map[\"cluster\"].unique()) },\n",
    "            color_discrete_sequence = px.colors.qualitative.Plotly,\n",
    "            title=\"Counties by Resilience Clusters\",\n",
    "            hover_data=[\n",
    "                \"County Name\",\n",
    "                \"Socioeconomic Resilience\",\n",
    "                \"Food Resilience\",\n",
    "                \"Healthcare Resilience\",\n",
    "                \"cluster\"\n",
    "            ],\n",
    "        )\n",
    "        fig.update_traces(marker_line_width=0.5)\n",
    "\n",
    "    # If the map toggle is Community Resilience Index (CRI)\n",
    "    else:\n",
    "        fig = px.choropleth(\n",
    "            df_map,\n",
    "            geojson=counties_geojson,\n",
    "            locations=\"fips\",\n",
    "            featureidkey=\"properties.GEOID\",\n",
    "            color=\"Community Resilience Index (CRI)\",\n",
    "            color_continuous_scale=\"Viridis\",\n",
    "            scope=\"usa\",\n",
    "            title=\"CRI by Georgia County\",\n",
    "            hover_data=[\n",
    "                \"County Name\",\n",
    "                \"Socioeconomic Resilience\",\n",
    "                \"Food Resilience\",\n",
    "                \"Healthcare Resilience\",\n",
    "                \"Community Resilience Index (CRI)\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Override the default hover template to include custom data\n",
    "    fig.update_traces(\n",
    "        hovertemplate=(\n",
    "            \"<b>%{customdata[0]}</b><br>\"\n",
    "            \"Socioeconomic: %{customdata[1]:.4f}<br>\"\n",
    "            \"Food: %{customdata[2]:.4f}<br>\"\n",
    "            \"Healthcare: %{customdata[3]:.4f}<br>\"\n",
    "            \"CRI: %{customdata[4]:.4f}<extra></extra>\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # To make sure NOAA warnings are shown properly with coloring already going on for CRI and Resilience Clusters,\n",
    "    # we need to set the border colors and widths based on the warning status\n",
    "    border_colors  = [\"red\" if w else \"#444\" for w in df_map[\"warning\"]]\n",
    "    border_widths  = [3 if w else 1 for w in df_map[\"warning\"]]\n",
    "    fig.update_traces(\n",
    "        marker_line_color=border_colors,\n",
    "        marker_line_width=border_widths\n",
    "    )\n",
    "\n",
    "\n",
    "    # Title alignment for the graph\n",
    "    fig.update_layout(title_x=0.3)\n",
    "\n",
    "\n",
    "    # Show the active NOAA warnings in the sidebar with the FIPS codes\n",
    "    codes = sorted(warning_fips)\n",
    "    if codes:\n",
    "        st.sidebar.write(\"Active alert FIPS codes:\", codes)\n",
    "    else:\n",
    "        st.sidebar.info(\"No active NOAA alerts for Georgia right now.\")\n",
    "\n",
    "    # Update the map layout\n",
    "    fig.update_geos(\n",
    "        fitbounds=\"locations\", visible=False,\n",
    "        lonaxis=dict(range=[-85.5, -80.5]),\n",
    "        lataxis=dict(range=[30, 35.5])\n",
    "    )\n",
    "    fig.update_layout(margin={\"t\": 30, \"b\": 0, \"l\": 0, \"r\": 0}, title_x=0.3)\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # Bar chart + Details\n",
    "    st.subheader(\"CRI Distribution\")\n",
    "    st.bar_chart(df_map.set_index(\"County Name\")[\"Community Resilience Index (CRI)\"])\n",
    "\n",
    "    if county != \"All\" and not df_map.empty:\n",
    "        r = df_map.iloc[0]\n",
    "        st.subheader(f\"Details: {county}\")\n",
    "        c1, c2, c3, c4 = st.columns(4)\n",
    "        c1.metric(\"Socioeconomic\", f\"{r['Socioeconomic Resilience']:.4f}\")\n",
    "        c2.metric(\"Food\",         f\"{r['Food Resilience']:.4f}\")\n",
    "        c3.metric(\"Healthcare\",   f\"{r['Healthcare Resilience']:.4f}\")\n",
    "        c4.metric(\"CRI\",          f\"{r['Community Resilience Index (CRI)']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.38:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run interactive_dashboard.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
